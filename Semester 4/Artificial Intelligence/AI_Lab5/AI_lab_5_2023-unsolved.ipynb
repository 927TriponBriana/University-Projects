{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3614e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ee7e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# model1 = nn.Sequential(OrderedDict([\n",
    "#    ('hidden', nn.\n",
    "# ]))\n",
    "\n",
    "# define the model architecture\n",
    "def create_model(hidden_size):\n",
    "    model = nn.Sequential(OrderedDict([\n",
    "        ('fc1', nn.Linear(4, hidden_size)),\n",
    "        ('relu1', nn.ReLU()),\n",
    "        ('fc2', nn.Linear(hidden_size, hidden_size)),\n",
    "        ('relu2', nn.ReLU()),\n",
    "        ('fc3', nn.Linear(hidden_size, 1)),\n",
    "        ('softmax', nn.Softmax(dim=1))\n",
    "    ]))\n",
    "    return model\n",
    "\n",
    "# create three models with different hidden layer sizes\n",
    "model1 = create_model(4)\n",
    "model2 = create_model(8)\n",
    "model3 = create_model(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "665ae958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Sequential(\n",
      "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Sequential(\n",
      "  (fc1): Linear(in_features=4, out_features=16, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)\n",
    "print(model2)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e26f0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#data_in = torch.tensor( ...\n",
    "\n",
    "# define the dataset\n",
    "X_train = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y_train = torch.tensor([[0], [1], [1], [2]], dtype=torch.float32)\n",
    "\n",
    "print(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4fb16bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]]) tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# data_target = torch.tensor( ...\n",
    "\n",
    "# evaluate the models on the test dataset\n",
    "X_test = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y_test = torch.tensor([[0], [1], [1], [2]], dtype=torch.float32)\n",
    "\n",
    "print(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69d920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# criterion = \n",
    "# optimizer = \n",
    "\n",
    "# define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.01)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.01)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cde91f6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4x2 and 4x4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# train model1\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     optimizer1\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 8\u001b[0m     output1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     loss1 \u001b[38;5;241m=\u001b[39m criterion(output1, y_train)\n\u001b[0;32m     10\u001b[0m     loss1\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aipy35\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aipy35\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aipy35\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aipy35\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x2 and 4x4)"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# Train the model\n",
    "\n",
    "# train the models\n",
    "for epoch in range(1000):\n",
    "    # train model1\n",
    "    optimizer1.zero_grad()\n",
    "    output1 = model1(X_train)\n",
    "    loss1 = criterion(output1, y_train)\n",
    "    loss1.backward()\n",
    "    optimizer1.step()\n",
    "\n",
    "    # train model2\n",
    "    optimizer2.zero_grad()\n",
    "    output2 = model2(X_train)\n",
    "    loss2 = criterion(output2, y_train)\n",
    "    loss2.backward()\n",
    "    optimizer2.step()\n",
    "\n",
    "    # train model3\n",
    "    optimizer3.zero_grad()\n",
    "    output3 = model3(X_train)\n",
    "    loss3 = criterion(output3, y_train)\n",
    "    loss3.backward()\n",
    "    optimizer3.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# visualize the resuts\n",
    "\n",
    "with torch.no_grad():\n",
    "    output1 = model1(X_test)\n",
    "    output2 = model2(X_test)\n",
    "    output3 = model3(X_test)\n",
    "\n",
    "    # compute the accuracy of each model\n",
    "    correct1 = (output1.argmax(dim=1) == y_test.squeeze()).sum().item()\n",
    "    correct2 = (output2.argmax(dim=1) == y_test.squeeze()).sum().item()\n",
    "    correct3 = (output3.argmax(dim=1) == y_test.squeeze()).sum().item()\n",
    "    accuracy1 = correct1 / len(X_test)\n",
    "    accuracy2 = correct2 / len(X_test)\n",
    "    accuracy3 = correct3 / len(X_test)\n",
    "\n",
    "    print('Model 1 accuracy:', accuracy1)\n",
    "    print('Model 2 accuracy:', accuracy2)\n",
    "    print('Model 3 accuracy:', accuracy3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c1a7518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 weights:\n",
      "fc1.weight tensor([[-0.2880,  0.4962,  0.2904,  0.0608],\n",
      "        [-0.0578,  0.2242,  0.0829,  0.2191],\n",
      "        [-0.2980, -0.3346, -0.1458,  0.3223],\n",
      "        [ 0.3710,  0.0166,  0.3362,  0.2298],\n",
      "        [ 0.2275, -0.0217,  0.1605, -0.2223],\n",
      "        [-0.4290, -0.2007,  0.1885,  0.0745],\n",
      "        [-0.2764, -0.3288, -0.3151,  0.3746],\n",
      "        [ 0.0128,  0.2940,  0.3878,  0.0368],\n",
      "        [ 0.4284, -0.3517, -0.3598,  0.4689],\n",
      "        [ 0.1523,  0.4966, -0.3357,  0.1330],\n",
      "        [ 0.4775,  0.1278, -0.4013,  0.3285],\n",
      "        [-0.3666, -0.0411, -0.0800, -0.4609],\n",
      "        [ 0.4972,  0.1323, -0.2423, -0.1331],\n",
      "        [-0.3430, -0.1319,  0.4275,  0.4478],\n",
      "        [-0.2150,  0.0028, -0.4273, -0.4808],\n",
      "        [ 0.0420, -0.0377, -0.1251, -0.4879]])\n",
      "fc1.bias tensor([ 0.0364, -0.1655,  0.2608,  0.4574,  0.0736, -0.0337, -0.3590,  0.2332,\n",
      "        -0.2145, -0.4708, -0.2647,  0.0539, -0.4629, -0.0058,  0.1331, -0.3255])\n",
      "fc2.weight tensor([[ 1.7774e-01, -2.8376e-02,  5.0588e-02, -1.0090e-01, -3.7772e-02,\n",
      "         -1.4222e-01,  1.6727e-02, -2.4782e-01, -1.0282e-01,  2.0079e-01,\n",
      "         -1.7057e-02, -1.3275e-01,  1.0116e-01, -5.3076e-03, -2.7857e-02,\n",
      "          3.0642e-02],\n",
      "        [-1.5324e-01, -1.4642e-01, -1.3168e-01, -1.7107e-01,  1.7607e-01,\n",
      "         -1.5746e-01, -1.9875e-01, -8.9706e-03,  1.6164e-01,  3.9002e-02,\n",
      "          1.5925e-01, -1.3506e-01, -2.2301e-01,  2.2450e-01,  1.2841e-01,\n",
      "          1.5797e-01],\n",
      "        [-1.5934e-01,  6.8039e-02, -2.4081e-01, -1.6544e-01, -2.4425e-01,\n",
      "         -2.2305e-01,  2.1983e-01, -1.5515e-01,  1.4986e-01,  5.8875e-02,\n",
      "         -2.0604e-01,  2.6890e-02,  1.2401e-01,  1.3474e-01, -8.8759e-02,\n",
      "         -1.9411e-01],\n",
      "        [-1.5777e-01,  7.2097e-02,  6.7178e-02,  9.8332e-02,  7.2065e-02,\n",
      "         -1.8961e-01, -1.4860e-01,  1.6118e-01, -1.0812e-01,  1.8636e-01,\n",
      "          1.0007e-01,  5.9814e-02,  6.3374e-02, -1.2661e-01, -1.2060e-02,\n",
      "         -8.5649e-02],\n",
      "        [ 8.9184e-02,  2.1233e-01,  2.4939e-01, -2.0518e-01, -3.7622e-02,\n",
      "         -2.7982e-02, -1.1586e-02,  6.5371e-02,  3.3231e-02, -7.2762e-02,\n",
      "         -1.9654e-01, -1.4227e-01, -1.1240e-02, -6.6009e-02, -3.3157e-02,\n",
      "         -1.3809e-01],\n",
      "        [-6.4177e-02, -7.6282e-02, -1.5094e-01,  2.2580e-01, -2.1284e-02,\n",
      "         -2.4462e-01, -6.9695e-02, -4.8322e-02, -2.1129e-01,  2.1694e-01,\n",
      "         -2.8172e-02, -8.2343e-02, -1.1084e-01, -9.5733e-02, -1.0139e-01,\n",
      "         -1.1540e-01],\n",
      "        [-1.9269e-01,  2.2086e-01,  2.0865e-01, -2.2413e-01, -8.1046e-02,\n",
      "         -1.4329e-01, -2.3775e-01, -6.6854e-02,  1.8602e-01, -1.2093e-01,\n",
      "         -3.5155e-02,  5.8663e-03,  6.2397e-02,  5.3497e-02, -2.0690e-01,\n",
      "         -4.6844e-02],\n",
      "        [-7.8995e-02, -1.7244e-01, -1.0357e-01,  9.6470e-02,  6.2971e-02,\n",
      "         -1.7658e-01, -1.0134e-01, -9.3367e-02,  3.4782e-02,  3.6667e-02,\n",
      "         -1.2270e-02,  4.2478e-02, -8.3775e-03, -2.2437e-01, -2.0497e-01,\n",
      "         -7.3928e-02],\n",
      "        [ 2.3598e-01,  7.1263e-02, -1.6219e-01, -2.9775e-02, -2.4192e-01,\n",
      "          2.2893e-01,  1.1771e-01, -1.2713e-01,  1.2515e-01, -2.0386e-01,\n",
      "         -4.3157e-02,  3.5153e-02,  1.7943e-02, -2.0351e-01, -1.6857e-01,\n",
      "          2.2672e-01],\n",
      "        [-1.6258e-02, -1.5503e-01,  1.1881e-01, -1.8452e-01,  1.5335e-01,\n",
      "         -1.2170e-01, -2.0123e-01, -5.5418e-03,  2.3328e-01,  3.6110e-02,\n",
      "          2.0125e-02,  2.4194e-01,  2.0213e-01, -1.4092e-02, -2.3325e-01,\n",
      "         -1.1361e-01],\n",
      "        [-1.6402e-01, -1.4359e-02, -1.0711e-01, -8.2625e-02,  1.5932e-01,\n",
      "         -1.8409e-01,  2.1337e-01,  7.5164e-02,  2.0176e-01,  1.4349e-01,\n",
      "         -2.3366e-01,  1.6179e-01,  1.1111e-01, -1.6169e-01, -1.6077e-01,\n",
      "         -6.3438e-02],\n",
      "        [ 3.1342e-02,  2.0908e-01, -8.6469e-02, -1.5419e-01, -2.1592e-01,\n",
      "         -1.2145e-01,  1.5664e-01,  5.2983e-02, -5.4610e-02, -5.6047e-02,\n",
      "          1.3305e-01,  3.0726e-02,  1.1853e-02, -2.2864e-02,  1.7034e-01,\n",
      "         -4.2412e-02],\n",
      "        [-2.4760e-01, -6.4206e-02, -3.3345e-02,  2.4006e-01,  1.4815e-01,\n",
      "          1.1209e-02, -3.8651e-04, -2.4250e-02, -1.6996e-01,  6.6408e-02,\n",
      "         -1.8434e-01,  1.9317e-01, -2.4946e-01, -1.1488e-01,  1.9348e-01,\n",
      "         -1.8091e-01],\n",
      "        [-1.2391e-01,  2.4646e-01, -1.4929e-01,  1.3994e-02,  1.6418e-01,\n",
      "          9.2247e-02, -1.0776e-01, -2.3096e-01, -1.1061e-01,  2.0626e-01,\n",
      "         -1.9164e-01,  1.4565e-01,  2.2128e-04, -6.5559e-02,  1.3954e-01,\n",
      "          2.3853e-01],\n",
      "        [ 7.4074e-02,  1.0771e-01,  1.2576e-01,  2.4518e-01,  9.2171e-02,\n",
      "         -6.8706e-02, -6.6321e-02, -4.9629e-02,  8.5081e-02, -8.9887e-02,\n",
      "          6.0448e-02,  1.2883e-01,  2.1763e-02,  1.8238e-01,  1.8199e-01,\n",
      "          2.7514e-02],\n",
      "        [ 1.9784e-01, -1.0761e-01, -2.2388e-01, -2.8342e-02,  2.3401e-01,\n",
      "         -1.8709e-01, -7.1159e-02,  1.5518e-01, -2.3338e-01,  6.2567e-02,\n",
      "         -1.8762e-01,  1.2911e-01, -4.9350e-02, -1.0805e-01, -2.4053e-01,\n",
      "         -1.6441e-01]])\n",
      "fc2.bias tensor([ 0.1018,  0.0101,  0.2049,  0.0173, -0.0384, -0.1209, -0.0724,  0.0450,\n",
      "        -0.2266,  0.2420,  0.1892, -0.0454,  0.1509, -0.0908,  0.1894,  0.0213])\n",
      "fc3.weight tensor([[ 0.0799, -0.1541,  0.0483,  0.1657,  0.1295,  0.0604,  0.0817, -0.0046,\n",
      "          0.1063, -0.1187, -0.1360,  0.1336,  0.0126,  0.0905,  0.1600, -0.0610]])\n",
      "fc3.bias tensor([-0.1220])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# print model wights\n",
    "# display the weights for the best performing model (model3)\n",
    "print('Model 3 weights:')\n",
    "for name, param in model3.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf09ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bea66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c65a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa58e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
